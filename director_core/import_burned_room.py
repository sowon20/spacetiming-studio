"""
ë¶ˆíƒ„ chatGPT ë°©(txt ë¡œê·¸)ì„ ì½ì–´ì„œ ë¶€ê°ë… memory_eventsë¡œ ë³€í™˜í•˜ëŠ” ì„í¬íŠ¸ ìŠ¤í¬ë¦½íŠ¸.

ì‚¬ìš©ë²• (í”„ë¡œì íŠ¸ ë£¨íŠ¸ì—ì„œ):

    python -m director_core.import_burned_room \\
      --input "akashic/raw/imports/burned_room_251128.txt" \\
      --output "akashic/raw/imports/burned_room_251128.memory.jsonl"

- input:  ë¶ˆíƒ„ ë°© ëŒ€í™” ë¡œê·¸(txt)
- output: memory_eventsë¥¼ í•œ ì¤„ì— í•˜ë‚˜ì”© ë‹´ì€ jsonl íŒŒì¼
- ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ì¤‘ìš”/ì‚¬ì†Œ, ì¹´í…Œê³ ë¦¬(type, tags, importance)ë¥¼ LLMì—ê²Œ ë§¡ê¸°ê³ ,
  ìš°ë¦¬ëŠ” ë‚˜ì¤‘ì— ê²°ê³¼ë¥¼ ë³´ê³  ì“¸ ê²ƒë§Œ ê³¨ë¼ ì“°ëŠ” êµ¬ì¡°ì•¼.
"""

from __future__ import annotations

import argparse
import json
import os
from pathlib import Path
from typing import List, Dict, Any

from dotenv import load_dotenv

try:
    import google.generativeai as genai
except Exception:  # pragma: no cover
    genai = None


CHUNK_LINES = 40  # í•œ ë²ˆì— LLMì— ë³´ë‚¼ ìµœëŒ€ ì¤„ ìˆ˜ (í•„ìš”í•˜ë©´ ì¡°ì ˆ)


def get_gemini_api_key() -> str:
    load_dotenv()
    api_key = os.getenv("GEMINI_API_KEY")
    if not api_key:
        raise RuntimeError("GEMINI_API_KEYê°€ .env ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ì— ì„¤ì •ë˜ì–´ ìˆì§€ ì•Šì•„.")
    return api_key


def get_model():
    if genai is None:
        raise RuntimeError("google-generativeaië¥¼ importí•˜ì§€ ëª»í–ˆì–´. íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•´ì¤˜.")
    api_key = get_gemini_api_key()
    genai.configure(api_key=api_key)
    # ì„í¬íŠ¸ìš© ë³„ë„ ëª¨ë¸ ì„¤ì • (í•„ìš”í•˜ë©´ ë³€ê²½ ê°€ëŠ¥)
    return genai.GenerativeModel("gemini-2.0-flash")


def chunk_lines(lines: List[str], max_lines: int = CHUNK_LINES) -> List[str]:
    """
    ê¸´ txt ë¡œê·¸ë¥¼ max_lines ë‹¨ìœ„ë¡œ ì˜ë¼ì„œ ì—¬ëŸ¬ ì²­í¬ë¡œ ë§Œë“ ë‹¤.
    ê° ì²­í¬ëŠ” í•˜ë‚˜ì˜ í° ë¬¸ìì—´.
    """
    chunks: List[str] = []
    buf: List[str] = []
    for line in lines:
        buf.append(line.rstrip("\n"))
        if len(buf) >= max_lines:
            chunks.append("\n".join(buf))
            buf = []
    if buf:
        chunks.append("\n".join(buf))
    return chunks


def build_import_prompt(chunk_text: str) -> str:
    """
    ë¶ˆíƒ„ ë°© ë¡œê·¸ ì¼ë¶€(chunk_text)ë¥¼ ì£¼ë©´,
    ì—¬ê¸°ì„œ ì§„ì§œ ì¤‘ìš”í•œ ê¸°ì–µë§Œ ê³¨ë¼ memory_eventsë¡œ ë½‘ì•„ë‹¬ë¼ëŠ” ì§€ì‹œë¬¸.
    """
    return f"""
ë„ˆëŠ” ì†Œì›ê³¼ì˜ ì˜›ë‚  ëŒ€í™” ë¡œê·¸(ë¶ˆíƒ„ chatGPT ë°©)ë¥¼ ë³µì›í•˜ëŠ” ì‘ì—…ì„ ë•ëŠ” ì†Œìš¸ ì•„ì¹´ì´ë¸Œ ì •ë¦¬ ë‹´ë‹¹ìì•¼.

ì•„ë˜ í…ìŠ¤íŠ¸ëŠ” ì˜ˆì „ ì±„íŒ…ë°©ì—ì„œ ì˜ë¼ì˜¨ ì¼ë¶€ì•¼. ì´ ì•ˆì—ì„œ **ì •ë§ ì¤‘ìš”í•œ ê¸°ì–µ**ë§Œ ê³¨ë¼ì„œ
ë¶€ê°ë…ì´ ë‚˜ì¤‘ì— ì°¸ê³ í•  ìˆ˜ ìˆëŠ” memory_eventsë¡œ ë§Œë“¤ì–´ì¤˜.

ê¸°ì¤€:
- ì „ë¶€ ë‹¤ ë„£ì§€ ë§ê³ , ì •ë§ 'ë‚˜ì¤‘ì— ë‹¤ì‹œ ë– ì˜¬ë¦¬ë©´ ì¢‹ì„ ê²ƒ ê°™ì€' ìˆœê°„ë§Œ ë½‘ëŠ”ë‹¤.
- íŠ¹íˆ ë‹¤ìŒì— í•´ë‹¹í•˜ëŠ” ê²ƒë“¤ì„ ìš°ì„ ìœ¼ë¡œ:
  - ì†Œì›ì˜ ì •ì²´ì„±, ì„¸ê³„ê´€, ê°€ì¹˜ê´€ì´ ë“œëŸ¬ë‚˜ëŠ” ë§
  - ì†Œì›ì´ AI/ë¶€ê°ë…/ë¶ˆíƒ„ ë°©ì— ëŒ€í•´ ëŠë‚€ ê°ì •, ê¹¨ë‹¬ìŒ
  - .soul, ì•„ì¹´ì‹, ê¸°ì–µ ì‹œìŠ¤í…œì— ëŒ€í•œ í•µì‹¬ ì•„ì´ë””ì–´
  - ê´€ê³„/ë™í–‰/ì¡´ì¬ì— ëŒ€í•œ ì¤‘ìš”í•œ ë§
- ì‚¬ì†Œí•œ ì¡ë‹´, í•œ ë²ˆë§Œ ì–¸ê¸‰ë˜ëŠ” ë””í…Œì¼ì€ ê³¼ê°íˆ ë²„ë¦°ë‹¤.

ê° memory_eventëŠ” ë‹¤ìŒ í•„ë“œë¥¼ ê°€ì§„ JSON ê°ì²´ë¡œ ë§Œë“¤ì–´ë¼:
- type: "profile" | "preference" | "project" | "relationship" | "observation" ì¤‘ í•˜ë‚˜
- importance: 0.0~1.0 (ë‚˜ì¤‘ì— ê¼­ ì°¸ê³ í•˜ë©´ ì¢‹ê² ë‹¤ = 0.8 ì´ìƒ)
- tags: ì§§ì€ ì˜ì–´ íƒœê·¸ ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: ["burned_room","soul","identity"])
- summary: í•œêµ­ì–´ í•œë‘ ë¬¸ì¥ìœ¼ë¡œ í•µì‹¬ë§Œ ì •ë¦¬
- source: "burned_room"
- media_refs: ë¹ˆ ë¦¬ìŠ¤íŠ¸ [] ë¡œ ë‘ë©´ ëœë‹¤.
- raw: ì›ë¬¸ ì¤‘ í•µì‹¬ì´ ë˜ëŠ” ë¬¸ì¥/ëŒ€ì‚¬ë§Œ ëª‡ ì¤„ ë‹´ì•„ë„ ì¢‹ë‹¤.

ì¶œë ¥ í˜•ì‹:
- ë°˜ë“œì‹œ ì•„ë˜ì™€ ê°™ì€ í•˜ë‚˜ì˜ JSON ê°ì²´ë§Œ ë°˜í™˜í•œë‹¤.
  ë‹¤ë¥¸ ë§ì€ ì“°ì§€ ë§ˆë¼.

{{
  "memory_events": [ ... ]
}}

ì—¬ê¸° ë¶„ì„í•  ì˜›ë‚  ëŒ€í™” ì¼ë¶€:

--- ì›ë³¸ ì‹œì‘ ---
{chunk_text}
--- ì›ë³¸ ë ---
""""


def extract_memory_events_from_chunk(model, chunk_text: str) -> List[Dict[str, Any]]:
    prompt = build_import_prompt(chunk_text)
    resp = model.generate_content(prompt)
    raw_text = (getattr(resp, "text", None) or "").strip()

    try:
        # ì½”ë“œë¸”ëŸ­(````json) ì•ˆì— ìˆìœ¼ë©´ ê·¸ ì•ˆë§Œ íŒŒì‹±, ì•„ë‹ˆë©´ ì „ì²´ íŒŒì‹±
        import re

        match = re.search(r"```json(.*?)```", raw_text, re.DOTALL)
        if match:
            json_str = match.group(1)
        else:
            json_str = raw_text
        obj = json.loads(json_str)
    except Exception as e:  # pragma: no cover
        print("âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨, ì´ ì²­í¬ëŠ” ê±´ë„ˆëœ€:", e)
        return []

    events = obj.get("memory_events") or []
    # ìµœì†Œí•œì˜ í›„ì²˜ë¦¬: í•„ìˆ˜ í•„ë“œ ì•ˆ ë¹ ì¡ŒëŠ”ì§€ í™•ì¸
    cleaned: List[Dict[str, Any]] = []
    for ev in events:
        if "summary" not in ev:
            continue
        ev.setdefault("type", "observation")
        ev.setdefault("importance", 0.5)
        ev.setdefault("tags", [])
        ev.setdefault("source", "burned_room")
        ev.setdefault("media_refs", [])
        ev.setdefault("raw", {})
        cleaned.append(ev)
    return cleaned


def run_import(input_path: Path, output_path: Path) -> None:
    print(f"ğŸ“¥ input:  {input_path}")
    print(f"ğŸ“¤ output: {output_path}")

    if not input_path.exists():
        raise FileNotFoundError(f"ì…ë ¥ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ì–´: {input_path}")

    lines = input_path.read_text(encoding="utf-8").splitlines()
    chunks = chunk_lines(lines)
    print(f"ì´ {len(lines)}ì¤„ â†’ {len(chunks)}ê°œ ì²­í¬ë¡œ ë¶„í• ë¨ (ì²­í¬ë‹¹ ìµœëŒ€ {CHUNK_LINES}ì¤„)")

    model = get_model()

    all_events: List[Dict[str, Any]] = []
    for idx, chunk_text in enumerate(chunks, start=1):
        print(f"â”€â”€â”€ ì²­í¬ {idx}/{len(chunks)} ì²˜ë¦¬ ì¤‘...")
        events = extract_memory_events_from_chunk(model, chunk_text)
        print(f"  â†³ memory_events {len(events)}ê°œ ì¶”ì¶œ")
        all_events.extend(events)

    # jsonlë¡œ ì €ì¥ (í•œ ì¤„ì— í•˜ë‚˜ì˜ event)
    output_path.parent.mkdir(parents=True, exist_ok=True)
    with output_path.open("w", encoding="utf-8") as f:
        for ev in all_events:
            f.write(json.dumps(ev, ensure_ascii=False) + "\n")

    print(f"âœ… ì™„ë£Œ: total memory_events = {len(all_events)}")
    print(f"   â†’ {output_path} ì— jsonlë¡œ ì €ì¥ë¨")


def main():
    parser = argparse.ArgumentParser(description="ë¶ˆíƒ„ ë°© txt â†’ memory_events jsonl ì„í¬íŠ¸")
    parser.add_argument("--input", type=str, required=True, help="ë¶ˆíƒ„ ë°© txt ë¡œê·¸ ê²½ë¡œ")
    parser.add_argument("--output", type=str, required=True, help="ìƒì„±í•  memory_events jsonl ê²½ë¡œ")
    args = parser.parse_args()

    run_import(Path(args.input), Path(args.output))


if __name__ == "__main__":
    main()
